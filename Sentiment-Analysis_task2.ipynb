{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dataset Link: (Take Any Dataset but avoid using benchmark data)\n",
    "# Tech : Pytorch or Tensorflow\n",
    "\n",
    "# Take any Dataset and perform any one task. (You are free to choose Tasks as per your understanding)\n",
    "\n",
    "# Tasks: Sentiment Analysis , Text Classification , Text Generation, Machine Translation, Text Summarization , Question Answering.\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import string \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "- First we write a function helping us to load data using torchtext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from csv ...\n",
      "dict_keys(['text', 'label'])\n",
      "build vocab success...\n",
      "construct iterator success...\n"
     ]
    }
   ],
   "source": [
    "def load_file(filepath, device, MAX_VOCAB_SIZE = 25_000):\n",
    "    # our tokenizer: removing the punctuation & spliting the sentence.\n",
    "    tokenizer = lambda x: str(x).translate(str.maketrans('', '', string.punctuation)).strip().split()\n",
    "    \n",
    "    # Step one defination of our fields. \n",
    "    TEXT = data.Field(sequential=True, lower=True, tokenize=tokenizer, fix_length=100)\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "    \n",
    "    print(\"loading from csv ...\")\n",
    "    tv_datafields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "    \n",
    "    # Step two construction our dataset.\n",
    "    train, valid, test = data.TabularDataset.splits(path=filepath,\n",
    "                                                    train=\"Train.csv\", validation=\"Valid.csv\",\n",
    "                                                    test=\"Test.csv\", format=\"csv\",\n",
    "                                                    skip_header=True, fields=tv_datafields)\n",
    "    print(train[0].__dict__.keys())\n",
    "    \n",
    "    \n",
    "    # Step three We should build_vocab for the field with use_vocab=True. \n",
    "    # If not we will get an error during the loop section.\n",
    "    TEXT.build_vocab(train, max_size = MAX_VOCAB_SIZE)\n",
    "    \n",
    "    print(\"build vocab success...\")\n",
    "    \n",
    "    # Step four construct our iterator to our dataset. \n",
    "    train_iter = data.BucketIterator(train, device=device, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                                     sort_within_batch=False, repeat=False)\n",
    "    valid_iter = data.BucketIterator(valid, device=device, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                                     sort_within_batch=False, repeat=False)\n",
    "    test_iter = data.BucketIterator(test, device=device, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                                     sort_within_batch=False, repeat=False)\n",
    "    print(\"construct iterator success...\")\n",
    "    return TEXT, LABEL, train, valid, test, train_iter, valid_iter, test_iter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TEXT, LABEL, train, valid, test, train_iter, valid_iter, test_iter = load_file('/kaggle/input/imdb-dataset-sentiment-analysis-in-csv-format', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the most common words in the vocabulary and their frequencies.\n",
    "\n",
    "And also we can use TEXT.vocab.itos & TEXT.vocab.stoi to get the transform between word and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 531191), ('and', 256916), ('a', 256838), ('of', 230759), ('to', 213654), ('is', 168231), ('in', 147587), ('it', 122699), ('i', 122016), ('this', 119667), ('that', 108871), ('br', 91033), ('was', 76180), ('as', 73134), ('for', 69460), ('with', 69327), ('movie', 66976), ('but', 65518), ('film', 59411), ('on', 53330)]\n",
      "['<unk>', '<pad>', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it']\n"
     ]
    }
   ],
   "source": [
    "# most common words and their frequencies.\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "\n",
    "# top ten index to words transform.\n",
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model \n",
    "\n",
    "build our RNN(LSTM) model using pytorch !\n",
    "\n",
    "Each Batch, text, is a tensor of size **\\[sentence length, batch_size\\]**. \n",
    "\n",
    "The input batch is then passed through the embedding layer to get embedded, which gives us a dense vector representation of our sentences. embedded is a tensor of size \\[sentence length, batch_size, embedding dim\\]\n",
    "\n",
    "embedded is the fed into the RNN. In some frameworks you must feed the initial hidden state, $h_0$, into RNN, however in Pytorch, if nno initial hidden state is passed as an argument it defaults to a tensor of all zeros.\n",
    "\n",
    "The RNN returns 2 tensors, output of size \\[sentence length, batch size, hidden dim\\] and hidden of size \\[1, batch_size, hidden_dim \\]. output is the concatenation of the hidden state from every time step, whereas hidden is simply the final hidden state. \n",
    "\n",
    "**squeeze method** : used to remove a dimension of size 1.\n",
    "\n",
    "Finally, we feed the last hidden state, hidden, through the linear layer, fc to produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text [sentence length, batch_size]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        # embedded = [sentence length, batch_size, emb dim]\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        # output = [sent len, batch_size, hid dim]\n",
    "        # hidden = [1, batch_size, hid dim]\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "print(INPUT_DIM)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = SentimentModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Now we will set up the training and then train the model.\n",
    "\n",
    "First we will create an optimizer. This is the algorithm we use to update the parameters of the module. Here we used the SGD. The first argument is the parameters will be update by the optimizer, the second is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define our loss function. In Pytorch this is commonly called a criterion.\n",
    "\n",
    "The loss function here is binary cross entropy with logits.\n",
    "\n",
    "Our model currently outputs an unbound real number. As our labels are either 0 or 1, we want to restrict the predictions to a number between 0 and 1. We do this using the sigmoid / logit function.\n",
    "\n",
    "We then use this bound scalar  to  calculate the loss using binary cross entropy.\n",
    "\n",
    "The  BCEWithLogitsLoss criterion carries out both the sigmoid and the binary cross entropy steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using .to we can place the model and the criterion on the GPU (if we have one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our criterion function calculates the loss, however we have to write our function to calculate the accuracy.\n",
    "\n",
    "This function first feeds the predictions through a sigmoid layer, squashing the values between 0 and 1, We then round them to the nearest integer.\n",
    "\n",
    "\n",
    "We then calculate how many rounded predictions equal the actual labels and average it across the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    '''\n",
    "    Return accuracy per batch ..\n",
    "    '''\n",
    "    \n",
    "    # round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        # note we must transform the batch.label into float or we will get an error later.\n",
    "        loss = criterion(predictions, batch.label.float())\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f\"[{i}/{len(iterator)}] : epoch_acc: {epoch_acc / len(iterator):.2f}\")\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            # prediction [batch_size]\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label.float())\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator),  epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time  / 60)\n",
    "    elapsed_secs = int(elapsed_time -  (elapsed_mins * 60))\n",
    "    return  elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199/1250] : epoch_acc: 0.08\n",
      "[399/1250] : epoch_acc: 0.16\n",
      "[599/1250] : epoch_acc: 0.24\n",
      "[799/1250] : epoch_acc: 0.32\n",
      "[999/1250] : epoch_acc: 0.40\n",
      "[1199/1250] : epoch_acc: 0.48\n",
      "Epoch:  01 | Epoch Time: 0m 8s\n",
      "\tTrain  Loss:  0.698 | Train Acc: 50.02%\n",
      "\tValid  Loss:  0.698 | Valid Acc: 49.44%\n",
      "[199/1250] : epoch_acc: 0.08\n",
      "[399/1250] : epoch_acc: 0.16\n",
      "[599/1250] : epoch_acc: 0.24\n",
      "[799/1250] : epoch_acc: 0.32\n",
      "[999/1250] : epoch_acc: 0.40\n",
      "[1199/1250] : epoch_acc: 0.49\n",
      "Epoch:  02 | Epoch Time: 0m 8s\n",
      "\tTrain  Loss:  0.695 | Train Acc: 50.69%\n",
      "\tValid  Loss:  0.696 | Valid Acc: 49.60%\n",
      "[199/1250] : epoch_acc: 0.08\n",
      "[399/1250] : epoch_acc: 0.16\n",
      "[599/1250] : epoch_acc: 0.24\n",
      "[799/1250] : epoch_acc: 0.33\n",
      "[999/1250] : epoch_acc: 0.41\n",
      "[1199/1250] : epoch_acc: 0.49\n",
      "Epoch:  03 | Epoch Time: 0m 8s\n",
      "\tTrain  Loss:  0.694 | Train Acc: 51.11%\n",
      "\tValid  Loss:  0.696 | Valid Acc: 49.76%\n",
      "[199/1250] : epoch_acc: 0.08\n",
      "[399/1250] : epoch_acc: 0.17\n",
      "[599/1250] : epoch_acc: 0.25\n",
      "[799/1250] : epoch_acc: 0.33\n",
      "[999/1250] : epoch_acc: 0.41\n",
      "[1199/1250] : epoch_acc: 0.49\n",
      "Epoch:  04 | Epoch Time: 0m 8s\n",
      "\tTrain  Loss:  0.693 | Train Acc: 51.35%\n",
      "\tValid  Loss:  0.695 | Valid Acc: 49.78%\n",
      "[199/1250] : epoch_acc: 0.08\n",
      "[399/1250] : epoch_acc: 0.17\n",
      "[599/1250] : epoch_acc: 0.25\n",
      "[799/1250] : epoch_acc: 0.33\n",
      "[999/1250] : epoch_acc: 0.41\n",
      "[1199/1250] : epoch_acc: 0.50\n",
      "Epoch:  05 | Epoch Time: 0m 8s\n",
      "\tTrain  Loss:  0.693 | Train Acc: 51.74%\n",
      "\tValid  Loss:  0.694 | Valid Acc: 49.96%\n"
     ]
    }
   ],
   "source": [
    "N_epoches = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_epoches):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'Sentiment-model.pt')\n",
    "        \n",
    "    print(f'Epoch:  {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain  Loss: {train_loss: .3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tValid  Loss: {valid_loss: .3f} | Valid Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the trival model of using pytorch & torchtext. You may find the loss is not really decreasing and the accuracy is poor. This is due to several issues with the model which can be improve in your own notebook. \n",
    "\n",
    "And I will also commit some notebook later.\n",
    "\n",
    "Finally the metric we actually care about, the test loss and accuracy, which we get from our parameters that gave us the best validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.692 | Test Acc: 52.57%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Sentiment-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Some improvements we can make are as follows:\n",
    "\n",
    "-  packed padded sequences\n",
    "-  pre-trained word embeddings\n",
    "-  different RNN architecture\n",
    "-  bidirectional RNN\n",
    "-  multi-layer RNN\n",
    "- regularization\n",
    "- a different optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
